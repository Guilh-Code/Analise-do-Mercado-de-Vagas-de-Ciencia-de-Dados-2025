{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c3e100",
   "metadata": {},
   "source": [
    "### Nosso Objetivo: \n",
    "\n",
    "\n",
    "Criar um modelo de Machine Learning que aprenda com as vagas existentes para prever o salario_avg de uma nova vaga que nunca vimos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "487cc807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados. Shape inicial: (944, 35)\n",
      "Shape ap√≥s remover sal√°rios nulos: (944, 35)\n",
      "Shape ap√≥s remover outliers: (942, 35)\n",
      "\n",
      "--- Amostra dos Dados Limpos ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>status</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>industry</th>\n",
       "      <th>ownership</th>\n",
       "      <th>company_size</th>\n",
       "      <th>...</th>\n",
       "      <th>tem_scikit_learning</th>\n",
       "      <th>tem_tensorflow</th>\n",
       "      <th>tem_pytorch</th>\n",
       "      <th>tem_azure</th>\n",
       "      <th>tem_gcp</th>\n",
       "      <th>tem_tableau</th>\n",
       "      <th>tem_pandas</th>\n",
       "      <th>tem_git</th>\n",
       "      <th>tem_java</th>\n",
       "      <th>tem_powerbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>S√™nior</td>\n",
       "      <td>H√≠brido</td>\n",
       "      <td>company_003</td>\n",
       "      <td>Grapevine, TX . Hybrid</td>\n",
       "      <td>17 days ago</td>\n",
       "      <td>Bentonville, AR, US</td>\n",
       "      <td>Varejo</td>\n",
       "      <td>P√∫blica</td>\n",
       "      <td>‚Ç¨352.44B</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>L√≠der</td>\n",
       "      <td>H√≠brido</td>\n",
       "      <td>company_005</td>\n",
       "      <td>Fort Worth, TX . Hybrid</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>Detroit, MI, US</td>\n",
       "      <td>Manufatura</td>\n",
       "      <td>P√∫blica</td>\n",
       "      <td>155,030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>S√™nior</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>company_007</td>\n",
       "      <td>Austin, TX . Toronto, Ontario, Canada . Kirkla...</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>Redwood City, CA, US</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>P√∫blica</td>\n",
       "      <td>25,930</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>S√™nior</td>\n",
       "      <td>H√≠brido</td>\n",
       "      <td>company_008</td>\n",
       "      <td>Chicago, IL . Scottsdale, AZ . Austin, TX . Hy...</td>\n",
       "      <td>8 days ago</td>\n",
       "      <td>San Jose, CA, US</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>P√∫blica</td>\n",
       "      <td>34,690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>N√£o Informado</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>company_009</td>\n",
       "      <td>On-site</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Stamford, CT, US</td>\n",
       "      <td>Finan√ßas</td>\n",
       "      <td>Privada</td>\n",
       "      <td>1,800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_title seniority_level      status      company  \\\n",
       "0  Cientista de Dados          S√™nior     H√≠brido  company_003   \n",
       "1  Cientista de Dados           L√≠der     H√≠brido  company_005   \n",
       "2  Cientista de Dados          S√™nior  Presencial  company_007   \n",
       "3  Cientista de Dados          S√™nior     H√≠brido  company_008   \n",
       "4  Cientista de Dados   N√£o Informado  Presencial  company_009   \n",
       "\n",
       "                                            location    post_date  \\\n",
       "0                             Grapevine, TX . Hybrid  17 days ago   \n",
       "1                            Fort Worth, TX . Hybrid  15 days ago   \n",
       "2  Austin, TX . Toronto, Ontario, Canada . Kirkla...  a month ago   \n",
       "3  Chicago, IL . Scottsdale, AZ . Austin, TX . Hy...   8 days ago   \n",
       "4                                            On-site   3 days ago   \n",
       "\n",
       "            headquarter    industry ownership company_size  ...  \\\n",
       "0   Bentonville, AR, US      Varejo   P√∫blica     ‚Ç¨352.44B  ...   \n",
       "1       Detroit, MI, US  Manufatura   P√∫blica      155,030  ...   \n",
       "2  Redwood City, CA, US  Tecnologia   P√∫blica       25,930  ...   \n",
       "3      San Jose, CA, US  Tecnologia   P√∫blica       34,690  ...   \n",
       "4      Stamford, CT, US    Finan√ßas   Privada        1,800  ...   \n",
       "\n",
       "  tem_scikit_learning tem_tensorflow tem_pytorch  tem_azure  tem_gcp  \\\n",
       "0                   0              1           0          0        0   \n",
       "1                   0              0           0          0        0   \n",
       "2                   0              0           0          0        1   \n",
       "3                   0              0           0          0        0   \n",
       "4                   0              0           0          0        0   \n",
       "\n",
       "   tem_tableau tem_pandas tem_git  tem_java  tem_powerbi  \n",
       "0            0          0       0         0            0  \n",
       "1            0          0       0         0            0  \n",
       "2            0          0       1         0            0  \n",
       "3            0          0       0         0            0  \n",
       "4            0          0       0         0            0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# --- ETAPA DE CARREGAMENTO E LIMPEZA INICIAL ---\n",
    "\n",
    "# Configura√ß√£o\n",
    "db_file_path = 'data_science_jobs.db'\n",
    "table_name = 'job_postings'\n",
    "\n",
    "# Carregando os Dados\n",
    "conn = sqlite3.connect(db_file_path)\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Dados carregados. Shape inicial: {df.shape}\")\n",
    "\n",
    "# --- LIMPEZA E VALIDA√á√ÉO ---\n",
    "\n",
    "# 1. (BOA PR√ÅTICA) Remover linhas onde o alvo (salario_avg) √© nulo\n",
    "df.dropna(subset=['salario_avg'], inplace=True)\n",
    "print(f\"Shape ap√≥s remover sal√°rios nulos: {df.shape}\")\n",
    "\n",
    "# 2. (A SOLU√á√ÉO FINAL) Remover outliers extremos de sal√°rio\n",
    "df = df[df['salario_avg'] < 2000000] # Mant√©m apenas as linhas com sal√°rio ABAIXO de 2 milh√µes\n",
    "print(f\"Shape ap√≥s remover outliers: {df.shape}\")\n",
    "\n",
    "\n",
    "# Exibe as 5 primeiras linhas do DataFrame limpo para verifica√ß√£o\n",
    "print(\"\\n--- Amostra dos Dados Limpos ---\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69651a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifica√ß√£o Geral do DataFrame (df.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 942 entries, 0 to 943\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   job_title             942 non-null    object \n",
      " 1   seniority_level       942 non-null    object \n",
      " 2   status                942 non-null    object \n",
      " 3   company               942 non-null    object \n",
      " 4   location              940 non-null    object \n",
      " 5   post_date             942 non-null    object \n",
      " 6   headquarter           942 non-null    object \n",
      " 7   industry              942 non-null    object \n",
      " 8   ownership             895 non-null    object \n",
      " 9   company_size          942 non-null    object \n",
      " 10  revenue               927 non-null    object \n",
      " 11  salary                942 non-null    object \n",
      " 12  skills                942 non-null    object \n",
      " 13  salario_min           942 non-null    float64\n",
      " 14  salario_max           942 non-null    float64\n",
      " 15  salario_avg           942 non-null    float64\n",
      " 16  estado                561 non-null    object \n",
      " 17  pais                  796 non-null    object \n",
      " 18  tem_python            942 non-null    int64  \n",
      " 19  tem_sql               942 non-null    int64  \n",
      " 20  tem_r                 942 non-null    int64  \n",
      " 21  tem_machine_learning  942 non-null    int64  \n",
      " 22  tem_aws               942 non-null    int64  \n",
      " 23  tem_spark             942 non-null    int64  \n",
      " 24  tem_deep_learning     942 non-null    int64  \n",
      " 25  tem_scikit_learning   942 non-null    int64  \n",
      " 26  tem_tensorflow        942 non-null    int64  \n",
      " 27  tem_pytorch           942 non-null    int64  \n",
      " 28  tem_azure             942 non-null    int64  \n",
      " 29  tem_gcp               942 non-null    int64  \n",
      " 30  tem_tableau           942 non-null    int64  \n",
      " 31  tem_pandas            942 non-null    int64  \n",
      " 32  tem_git               942 non-null    int64  \n",
      " 33  tem_java              942 non-null    int64  \n",
      " 34  tem_powerbi           942 non-null    int64  \n",
      "dtypes: float64(3), int64(17), object(15)\n",
      "memory usage: 264.9+ KB\n",
      "\n",
      "\n",
      "--- Resumo Estat√≠stico Completo do DataFrame (df.describe()) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>status</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>industry</th>\n",
       "      <th>ownership</th>\n",
       "      <th>company_size</th>\n",
       "      <th>...</th>\n",
       "      <th>tem_scikit_learning</th>\n",
       "      <th>tem_tensorflow</th>\n",
       "      <th>tem_pytorch</th>\n",
       "      <th>tem_azure</th>\n",
       "      <th>tem_gcp</th>\n",
       "      <th>tem_tableau</th>\n",
       "      <th>tem_pandas</th>\n",
       "      <th>tem_git</th>\n",
       "      <th>tem_java</th>\n",
       "      <th>tem_powerbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>940</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>895</td>\n",
       "      <td>942</td>\n",
       "      <td>...</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>420</td>\n",
       "      <td>429</td>\n",
       "      <td>42</td>\n",
       "      <td>197</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>S√™nior</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>company_134</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>San Francisco, CA, US</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>P√∫blica</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>854</td>\n",
       "      <td>628</td>\n",
       "      <td>363</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>167</td>\n",
       "      <td>91</td>\n",
       "      <td>580</td>\n",
       "      <td>579</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>0.175159</td>\n",
       "      <td>0.157113</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>0.111465</td>\n",
       "      <td>0.123142</td>\n",
       "      <td>0.080679</td>\n",
       "      <td>0.069002</td>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.026539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295573</td>\n",
       "      <td>0.380305</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.369032</td>\n",
       "      <td>0.314874</td>\n",
       "      <td>0.328775</td>\n",
       "      <td>0.272487</td>\n",
       "      <td>0.253592</td>\n",
       "      <td>0.267517</td>\n",
       "      <td>0.160818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 job_title seniority_level      status      company  \\\n",
       "count                  942             942         942          942   \n",
       "unique                   5               5           4          420   \n",
       "top     Cientista de Dados          S√™nior  Presencial  company_134   \n",
       "freq                   854             628         363           30   \n",
       "mean                   NaN             NaN         NaN          NaN   \n",
       "std                    NaN             NaN         NaN          NaN   \n",
       "min                    NaN             NaN         NaN          NaN   \n",
       "25%                    NaN             NaN         NaN          NaN   \n",
       "50%                    NaN             NaN         NaN          NaN   \n",
       "75%                    NaN             NaN         NaN          NaN   \n",
       "max                    NaN             NaN         NaN          NaN   \n",
       "\n",
       "                           location    post_date            headquarter  \\\n",
       "count                           940          942                    942   \n",
       "unique                          429           42                    197   \n",
       "top     Bengaluru, Karnataka, India  a month ago  San Francisco, CA, US   \n",
       "freq                             52          167                     91   \n",
       "mean                            NaN          NaN                    NaN   \n",
       "std                             NaN          NaN                    NaN   \n",
       "min                             NaN          NaN                    NaN   \n",
       "25%                             NaN          NaN                    NaN   \n",
       "50%                             NaN          NaN                    NaN   \n",
       "75%                             NaN          NaN                    NaN   \n",
       "max                             NaN          NaN                    NaN   \n",
       "\n",
       "          industry ownership company_size  ... tem_scikit_learning  \\\n",
       "count          942       895          942  ...          942.000000   \n",
       "unique           8         2          510  ...                 NaN   \n",
       "top     Tecnologia   P√∫blica          900  ...                 NaN   \n",
       "freq           580       579           18  ...                 NaN   \n",
       "mean           NaN       NaN          NaN  ...            0.096603   \n",
       "std            NaN       NaN          NaN  ...            0.295573   \n",
       "min            NaN       NaN          NaN  ...            0.000000   \n",
       "25%            NaN       NaN          NaN  ...            0.000000   \n",
       "50%            NaN       NaN          NaN  ...            0.000000   \n",
       "75%            NaN       NaN          NaN  ...            0.000000   \n",
       "max            NaN       NaN          NaN  ...            1.000000   \n",
       "\n",
       "       tem_tensorflow tem_pytorch   tem_azure     tem_gcp  tem_tableau  \\\n",
       "count      942.000000  942.000000  942.000000  942.000000   942.000000   \n",
       "unique            NaN         NaN         NaN         NaN          NaN   \n",
       "top               NaN         NaN         NaN         NaN          NaN   \n",
       "freq              NaN         NaN         NaN         NaN          NaN   \n",
       "mean         0.175159    0.157113    0.162420    0.111465     0.123142   \n",
       "std          0.380305    0.364100    0.369032    0.314874     0.328775   \n",
       "min          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "25%          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "50%          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "75%          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "max          1.000000    1.000000    1.000000    1.000000     1.000000   \n",
       "\n",
       "        tem_pandas     tem_git    tem_java  tem_powerbi  \n",
       "count   942.000000  942.000000  942.000000   942.000000  \n",
       "unique         NaN         NaN         NaN          NaN  \n",
       "top            NaN         NaN         NaN          NaN  \n",
       "freq           NaN         NaN         NaN          NaN  \n",
       "mean      0.080679    0.069002    0.077495     0.026539  \n",
       "std       0.272487    0.253592    0.267517     0.160818  \n",
       "min       0.000000    0.000000    0.000000     0.000000  \n",
       "25%       0.000000    0.000000    0.000000     0.000000  \n",
       "50%       0.000000    0.000000    0.000000     0.000000  \n",
       "75%       0.000000    0.000000    0.000000     0.000000  \n",
       "max       1.000000    1.000000    1.000000     1.000000  \n",
       "\n",
       "[11 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Coloque esta c√©lula logo ap√≥s o carregamento inicial do df\n",
    "\n",
    "print(\"--- Verifica√ß√£o Geral do DataFrame (df.info()) ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\\n--- Resumo Estat√≠stico Completo do DataFrame (df.describe()) ---\")\n",
    "# O include='all' mostra estat√≠sticas para colunas de texto e num√©ricas\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64118a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vaga(s) com Sal√°rio Extremo Encontrada(s) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>status</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>industry</th>\n",
       "      <th>ownership</th>\n",
       "      <th>company_size</th>\n",
       "      <th>...</th>\n",
       "      <th>tem_scikit_learning</th>\n",
       "      <th>tem_tensorflow</th>\n",
       "      <th>tem_pytorch</th>\n",
       "      <th>tem_azure</th>\n",
       "      <th>tem_gcp</th>\n",
       "      <th>tem_tableau</th>\n",
       "      <th>tem_pandas</th>\n",
       "      <th>tem_git</th>\n",
       "      <th>tem_java</th>\n",
       "      <th>tem_powerbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_title, seniority_level, status, company, location, post_date, headquarter, industry, ownership, company_size, revenue, salary, skills, salario_min, salario_max, salario_avg, estado, pais, tem_python, tem_sql, tem_r, tem_machine_learning, tem_aws, tem_spark, tem_deep_learning, tem_scikit_learning, tem_tensorflow, tem_pytorch, tem_azure, tem_gcp, tem_tableau, tem_pandas, tem_git, tem_java, tem_powerbi]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vamos encontrar a(s) vaga(s) com sal√°rio astron√¥mico\n",
    "outliers = df[df['salario_avg'] > 2000000] # Filtra o DataFrame para sal√°rios maiores que 2 milh√µes\n",
    "\n",
    "print(\"--- Vaga(s) com Sal√°rio Extremo Encontrada(s) ---\")\n",
    "display(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612383d1",
   "metadata": {},
   "source": [
    "### Vamos dividir nossa constru√ß√£o do modelo em etapas claras:\n",
    "\n",
    "- Etapa 1: Sele√ß√£o e Prepara√ß√£o das Features (Onde estamos agora).\n",
    "\n",
    "- Etapa 2: Pr√©-processamento e Codifica√ß√£o (Transformando tudo em n√∫meros).\n",
    "\n",
    "- Etapa 3: Divis√£o dos Dados (Treino e Teste).\n",
    "\n",
    "- Etapa 4: Escolha e Treinamento do Modelo.\n",
    "\n",
    "- Etapa 5: Avalia√ß√£o do Modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ffb798",
   "metadata": {},
   "source": [
    "## Etapa 1: Selecionando as Armas (Features) e o Alvo (Target)\n",
    "\n",
    "1. O Alvo (Target): O que voc√™ quer que eu aprenda a prever? ( y )\n",
    "\n",
    "2. As Pistas (Features): Que informa√ß√µes voc√™ vai me dar para que eu possa fazer a previs√£o? ( x )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74dc18b",
   "metadata": {},
   "source": [
    "### O nosso Alvo (y): \n",
    "√â f√°cil. Queremos prever o sal√°rio. A coluna perfeita para isso √© a salario_avg que n√≥s criamos.\n",
    "\n",
    "\n",
    "### As nossas Pistas (X): \n",
    "Aqui entra a parte estrat√©gica. Quais colunas do nosso banco de dados s√£o pistas √∫teis para adivinhar o sal√°rio?\n",
    "\n",
    "- job_title, seniority_level, status, industry: Com certeza! S√£o muito importantes.\n",
    "- pais, estado: Sim, o local influencia no sal√°rio.\n",
    "- tem_python, tem_sql, etc.: Absolutamente! As habilidades s√£o um fator chave.\n",
    "\n",
    "E quais colunas devemos EXCLUIR das pistas?\n",
    "\n",
    "- salary, salario_min, salario_max, salario_avg: NUNCA podemos usar o pr√≥prio alvo ou suas varia√ß√µes como uma pista. Seria como dar a resposta da prova para o aluno. Isso se chama data leakage (vazamento de dados) e √© o erro n√∫mero 1 em projetos de ML.\n",
    "- location, skills: As colunas de texto originais. Elas s√£o \"sujas\" e n√≥s j√° extra√≠mos as informa√ß√µes importantes delas para as novas colunas.\n",
    "- company, post_date, headquarter: S√£o identificadores, datas em formato de texto ou informa√ß√µes que j√° foram representadas de forma melhor (pais, estado). Por agora, vamos deix√°-las de fora para manter nosso primeiro modelo simples e forte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fef75c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Amostra do Alvo (y) ---\n",
      "0    150705.0\n",
      "1    118733.0\n",
      "2    127273.0\n",
      "3    153599.5\n",
      "4    171254.5\n",
      "Name: salario_avg, dtype: float64\n",
      "\n",
      "--- Amostra das Features (X) ---\n",
      "            job_title seniority_level      status    industry ownership  \\\n",
      "0  Cientista de Dados          S√™nior     H√≠brido      Varejo   P√∫blica   \n",
      "1  Cientista de Dados           L√≠der     H√≠brido  Manufatura   P√∫blica   \n",
      "2  Cientista de Dados          S√™nior  Presencial  Tecnologia   P√∫blica   \n",
      "3  Cientista de Dados          S√™nior     H√≠brido  Tecnologia   P√∫blica   \n",
      "4  Cientista de Dados   N√£o Informado  Presencial    Finan√ßas   Privada   \n",
      "\n",
      "            pais         estado  tem_python  tem_sql  tem_r  ...  \\\n",
      "0             US             TX           1        0      1  ...   \n",
      "1             US             TX           1        1      1  ...   \n",
      "2             CA  N√£o Informado           1        1      0  ...   \n",
      "3             US             IL           1        1      1  ...   \n",
      "4  N√£o Informado  N√£o Informado           0        0      0  ...   \n",
      "\n",
      "   tem_scikit_learning  tem_tensorflow  tem_pytorch  tem_azure  tem_gcp  \\\n",
      "0                    0               1            0          0        0   \n",
      "1                    0               0            0          0        0   \n",
      "2                    0               0            0          0        1   \n",
      "3                    0               0            0          0        0   \n",
      "4                    0               0            0          0        0   \n",
      "\n",
      "   tem_tableau  tem_pandas  tem_git  tem_java  tem_powerbi  \n",
      "0            0           0        0         0            0  \n",
      "1            0           0        0         0            0  \n",
      "2            0           0        1         0            0  \n",
      "3            0           0        0         0            0  \n",
      "4            0           0        0         0            0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Formato de X (linhas, colunas): (942, 24)\n",
      "Formato de y (linhas,): (942,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilh\\AppData\\Local\\Temp\\ipykernel_11672\\3174086559.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(\"N√£o Informado\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ---  Etapa 1: Sele√ß√£o de Features e target  ---\n",
    "\n",
    "# 1. Definir o Alvo (Target)\n",
    "# A vari√°vel 'y' vai conter apenas a coluna que queremos prever.\n",
    "target = 'salario_avg'\n",
    "y = df[target]\n",
    "\n",
    "# 2. Definir as Pistas (Features)\n",
    "# Criamos uma lista com os nomes de todas as colunas que servir√£o como \"pistas\" para o modelo.\n",
    "features = [\n",
    "    'job_title', 'seniority_level', 'status', 'industry', 'ownership',\n",
    "    'pais', 'estado',\n",
    "    'tem_python', 'tem_sql', 'tem_r', 'tem_machine_learning', 'tem_aws',\n",
    "    'tem_spark', 'tem_deep_learning', 'tem_scikit_learning', 'tem_tensorflow',\n",
    "    'tem_pytorch', 'tem_azure', 'tem_gcp', 'tem_tableau', 'tem_pandas',\n",
    "    'tem_git', 'tem_java', 'tem_powerbi'\n",
    "]\n",
    "X = df[features]\n",
    "\n",
    "# Tratamento de valores nulos ANTES do encoding\n",
    "X.fillna(\"N√£o Informado\", inplace=True)\n",
    "\n",
    "# 3. Verificar o resultado\n",
    "print(\"--- Amostra do Alvo (y) ---\")\n",
    "print(y.head())\n",
    "print(\"\\n--- Amostra das Features (X) ---\")\n",
    "print(X.head())\n",
    "\n",
    "print(f\"\\nFormato de X (linhas, colunas): {X.shape}\")\n",
    "print(f\"Formato de y (linhas,): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353204a",
   "metadata": {},
   "source": [
    "## Etapa 2: Pr√©-processamento e Codifica√ß√£o (One-Hot Encoding)\n",
    "\n",
    "O Problema: Temos colunas como job_title com valores 'Cientista de Dados', 'Engenheiro de Dados', etc. N√£o podemos simplesmente substituir 'Cientista de Dados' por 1 e 'Engenheiro de Dados' por 2, pois isso criaria uma rela√ß√£o matem√°tica falsa (como se um Engenheiro fosse \"o dobro\" de um Cientista), o que confundiria o modelo.\n",
    "\n",
    "A Solu√ß√£o: One-Hot Encoding\n",
    "A t√©cnica correta se chama One-Hot Encoding. √â um nome complicado para uma ideia muito simples, que eu chamo de \"T√©cnica do Interruptor\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc59c64",
   "metadata": {},
   "source": [
    "Imagine a coluna status com 3 op√ß√µes: 'Presencial', 'H√≠brido', 'Remoto'.\n",
    "O One-Hot Encoding vai fazer o seguinte:\n",
    "\n",
    "1. Ele apaga a coluna status original.\n",
    "\n",
    "2. Ele cria novas colunas, uma para cada op√ß√£o poss√≠vel, como se fossem interruptores: status_Presencial, status_H√≠brido, status_Remoto.\n",
    "\n",
    "3. Para cada vaga, ele \"liga\" (1) apenas o interruptor correspondente e deixa \n",
    "os outros \"desligados\" (0).\n",
    "\n",
    "\n",
    "Isso transforma uma √∫nica coluna de texto em m√∫ltiplas colunas de 0s e 1s, sem criar rela√ß√µes falsas. O modelo agora entende perfeitamente a categoria de cada vaga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b15418f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Amostra das Features ap√≥s o One-Hot Encoding ---\n",
      "   tem_python  tem_sql  tem_r  tem_machine_learning  tem_aws  tem_spark  \\\n",
      "0           1        0      1                     1        0          1   \n",
      "1           1        1      1                     1        0          1   \n",
      "2           1        1      0                     1        1          0   \n",
      "3           1        1      1                     0        0          0   \n",
      "4           0        0      0                     0        0          0   \n",
      "\n",
      "   tem_deep_learning  tem_scikit_learning  tem_tensorflow  tem_pytorch  ...  \\\n",
      "0                  0                    0               1            0  ...   \n",
      "1                  0                    0               0            0  ...   \n",
      "2                  1                    0               0            0  ...   \n",
      "3                  0                    0               0            0  ...   \n",
      "4                  0                    0               0            0  ...   \n",
      "\n",
      "   estado_ON  estado_OR  estado_PA  estado_TN  estado_TX  estado_UN  \\\n",
      "0          0          0          0          0          1          0   \n",
      "1          0          0          0          0          1          0   \n",
      "2          0          0          0          0          0          0   \n",
      "3          0          0          0          0          0          0   \n",
      "4          0          0          0          0          0          0   \n",
      "\n",
      "   estado_US  estado_VA  estado_WA  estado_WI  \n",
      "0          0          0          0          0  \n",
      "1          0          0          0          0  \n",
      "2          0          0          0          0  \n",
      "3          0          0          0          0  \n",
      "4          0          0          0          0  \n",
      "\n",
      "[5 rows x 86 columns]\n",
      "\n",
      "--- Mudan√ßa no Formato do DataFrame ---\n",
      "Formato original de X (antes do encoding): (942, 24)\n",
      "Formato de X_encoded (ap√≥s o encoding): (942, 86)\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 2: Pr√©-processamento e Codifica√ß√£o (One-Hot Encoding) ---\n",
    "\n",
    "# O pandas tem uma fun√ß√£o \"m√°gica\" para isso chamada get_dummies().\n",
    "# Ela encontra todas as colunas que n√£o s√£o num√©ricas no DataFrame X e aplica a \"T√©cnica do Interruptor\".\n",
    "# O par√¢metro drop_first=True √© uma boa pr√°tica para evitar redund√¢ncia de dados, o que pode ajudar o modelo.\n",
    "X_encoded = pd.get_dummies(X, drop_first=True).astype(int)\n",
    "\n",
    "# --- Verifica√ß√£o ---\n",
    "print(\"--- Amostra das Features ap√≥s o One-Hot Encoding ---\")\n",
    "print(X_encoded.head())\n",
    "\n",
    "print(\"\\n--- Mudan√ßa no Formato do DataFrame ---\")\n",
    "print(f\"Formato original de X (antes do encoding): {X.shape}\")\n",
    "print(f\"Formato de X_encoded (ap√≥s o encoding): {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f44dcd",
   "metadata": {},
   "source": [
    "## Etapa 3: Divis√£o dos Dados (Treino e Teste)\n",
    "\n",
    "Como falamos antes, precisamos separar nossos dados. Vamos usar a maior parte deles (geralmente 80%) para treinar o modelo. Os 20% restantes vamos guardar em um \"cofre\" e s√≥ usar no final, para fazer uma \"prova final\" e ver se o modelo √© bom com dados que ele nunca viu antes.\n",
    "\n",
    "A biblioteca scikit-learn, que √© o padr√£o da ind√∫stria para ML em Python, tem uma fun√ß√£o perfeita para isso: a train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06af2e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Formato dos Dados de Treino ---\n",
      "Formato de X_train: (753, 86)\n",
      "Formato de y_train: (753,)\n",
      "\n",
      "--- Formato dos Dados de Teste ---\n",
      "Formato de X_test: (189, 86)\n",
      "Formato de y_test: (189,)\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 3: Divis√£o dos Dados em Treino e Teste ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Esta fun√ß√£o vai embaralhar e dividir nossos dados em 4 partes:\n",
    "\n",
    "# X_train, y_train: 80% dos dados para o modelo aprender.\n",
    "# X_test, y_test: 20% dos dados para testarmos o modelo no final.\n",
    "# random_state=42: √â como uma \"semente\" para o embaralhamento. Usar um n√∫mero fixo grande que a divis√£o seja sempre a mesma, tornando nosso experimento reprodut√≠vel.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Verifica√ß√£o ---\n",
    "print(\"--- Formato dos Dados de Treino ---\")\n",
    "print(f\"Formato de X_train: {X_train.shape}\")\n",
    "print(f\"Formato de y_train: {y_train.shape}\")\n",
    "\n",
    "print(\"\\n--- Formato dos Dados de Teste ---\")\n",
    "print(f\"Formato de X_test: {X_test.shape}\")\n",
    "print(f\"Formato de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2c972",
   "metadata": {},
   "source": [
    "O \"Desempacotamento\" M√°gico do Python\n",
    "A fun√ß√£o train_test_split n√£o retorna 4 vari√°veis soltas. Na verdade, ela retorna uma √∫nica coisa: uma estrutura de dados chamada tupla, que cont√©m 4 elementos dentro dela, sempre na mesma ordem.\n",
    "\n",
    "A documenta√ß√£o da scikit-learn garante que a ordem de retorno √© sempre:\n",
    "\n",
    "1. O conjunto de treino das features (X_train)\n",
    "\n",
    "2. O conjunto de teste das features (X_test)\n",
    "\n",
    "3. O conjunto de treino do alvo (y_train)\n",
    "\n",
    "4. O conjunto de teste do alvo (y_test)\n",
    "\n",
    "Ordem que escrevemos X_train, X_test, y_train, y_test √© fixa e obrigat√≥ria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b1611",
   "metadata": {},
   "source": [
    "## Etapa 4: Escolhendo o C√©rebro (O Algoritmo) e Treinando o Modelo\n",
    "\n",
    "Existem dezenas de algoritmos, cada um com uma forma diferente de \"pensar\". Para o nosso primeiro projeto, vamos come√ßar com um dos mais fundamentais e importantes: a Regress√£o Linear (LinearRegression).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b89a41",
   "metadata": {},
   "source": [
    "O que √© a Regress√£o Linear?\n",
    "Pense nela como um detetive que tenta encontrar a \"f√≥rmula\" ou a \"receita\" do sal√°rio. Ele vai olhar para todas as nossas features (tem_python, seniority_level_S√™nior, pais_US, etc.) e atribuir um \"peso\" para cada uma.\n",
    "\n",
    "- Ele pode aprender que seniority_level_S√™nior tem um peso positivo alto (aumenta o sal√°rio).\n",
    "\n",
    "- Pode aprender que tem_python tem um peso positivo moderado.\n",
    "\n",
    "- Pode aprender que job_title_Analista de Dados tem um peso negativo (diminui o sal√°rio em rela√ß√£o √† m√©dia).\n",
    "\n",
    "O \"treinamento\" do modelo √© o processo de encontrar os valores exatos para todos esses pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7c82144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspe√ß√£o Profunda dos Dados de Treino ---\n",
      "Tipo de dado de X_train (array interno): int32\n",
      "Tipo de dado de y_train (array interno): float64\n",
      "Todos os valores em X_train s√£o finitos? True\n",
      "Todos os valores em y_train s√£o finitos? True\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA DE DIAGN√ìSTICO DE N√çVEL PROFUNDO ---\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Inspe√ß√£o Profunda dos Dados de Treino ---\")\n",
    "\n",
    "# 1. Verificar o tipo de dado do array num√©rico que o modelo realmente recebe\n",
    "print(f\"Tipo de dado de X_train (array interno): {X_train.values.dtype}\")\n",
    "print(f\"Tipo de dado de y_train (array interno): {y_train.values.dtype}\")\n",
    "\n",
    "# 2. A verifica√ß√£o definitiva: TODOS os valores s√£o finitos (n√£o-nulos E n√£o-infinitos)?\n",
    "print(f\"Todos os valores em X_train s√£o finitos? {np.isfinite(X_train.values).all()}\")\n",
    "print(f\"Todos os valores em y_train s√£o finitos? {np.isfinite(y_train.values).all()}\")\n",
    "print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "974d9ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo RandomForest treinado com sucesso! üå≥üå≥üå≥\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 4: Escolha e Treinamento do Modelo (VERS√ÉO COM RANDOM FOREST) ---\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. Criar o modelo\n",
    "# Trocamos o c√©rebro! Em vez de LinearRegression, usamos RandomForestRegressor.\n",
    "# random_state=42 garante que a \"floresta\" seja sempre criada da mesma forma, para reprodutibilidade.\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 2. Treinar o modelo\n",
    "# A M√ÅGICA: O comando .fit() √© EXATAMENTE O MESMO!\n",
    "# O scikit-learn tem uma API consistente, n√£o importa o qu√£o complexo seja o modelo.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Verifica√ß√£o\n",
    "print(\"Modelo RandomForest treinado com sucesso! üå≥üå≥üå≥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd08b7e",
   "metadata": {},
   "source": [
    "## Etapa 5: A Prova Final (Avaliando o Desempenho do Modelo)\n",
    "\n",
    "No entanto, para um modelo de Regress√£o (que prev√™ um n√∫mero, como o sal√°rio), n√£o usamos \"porcentagem de acerto\", porque seria imposs√≠vel o modelo acertar o valor exato sempre (prever ‚Ç¨145.231,78 em vez de ‚Ç¨145.231,80 j√° seria um \"erro\").\n",
    "\n",
    "Em vez disso, usamos outras m√©tricas para saber se ele est√° \"chegando perto\". As duas mais importantes para n√≥s ser√£o:\n",
    "\n",
    "### 1. MAE (Mean Absolute Error - Erro M√©dio Absoluto):\n",
    "\n",
    "- O que √©? Em m√©dia, quantos euros o nosso modelo erra a previs√£o (para mais ou para menos).\n",
    "\n",
    "- Como ler? Se o MAE for ‚Ç¨10.000, significa que, na m√©dia, as previs√µes do nosso modelo est√£o a ‚Ç¨10.000 de dist√¢ncia do sal√°rio real. Um MAE menor √© melhor.\n",
    "\n",
    "### 2. R¬≤ (R-quadrado ou Coeficiente de Determina√ß√£o):\n",
    "\n",
    "- O que √©? Essa √© a m√©trica que mais se aproxima da sua ideia de \"porcentagem\". Ela nos diz que porcentagem da varia√ß√£o dos sal√°rios o nosso modelo consegue explicar com base nas features que demos a ele.\n",
    "\n",
    "- Como ler? O valor vai de 0 a 1 (ou 0% a 100%). Um R¬≤ de 0.65, por exemplo, significa que nosso modelo consegue explicar 65% dos motivos que fazem um sal√°rio ser alto ou baixo. O resto (35%) se deve a fatores que n√£o est√£o nos nossos dados (sorte, habilidade de negocia√ß√£o, etc.). Um R¬≤ maior √© melhor. Para um problema complexo como sal√°rios, um R¬≤ acima de 0.60 ou 0.70 j√° √© considerado um bom resultado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2f3dc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avalia√ß√£o do Modelo RandomForest ---\n",
      "Erro M√©dio Absoluto (MAE): ‚Ç¨ 29,514.79\n",
      "Coeficiente de Determina√ß√£o (R¬≤): 60.07%\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 5: Avalia√ß√£o do Modelo ---\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1. Fazer as previs√µes no conjunto de teste\n",
    "# Usamos o comando .predict() nos dados de teste (X_test) para ver o que o modelo \"adivinha\".\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calcular as m√©tricas\n",
    "# Comparamos as previs√µes (y_pred) com as respostas reais (y_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 3. Exibir os resultados\n",
    "print(\"--- Avalia√ß√£o do Modelo RandomForest ---\")\n",
    "print(f\"Erro M√©dio Absoluto (MAE): ‚Ç¨ {mae:,.2f}\")\n",
    "print(f\"Coeficiente de Determina√ß√£o (R¬≤): {r2:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b0b06",
   "metadata": {},
   "source": [
    "## Etapa 6: Otimizando o Modelo (Ajuste de Hiperpar√¢metros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dca8b",
   "metadata": {},
   "source": [
    "### o Ajuste de Hiperpar√¢metros.\n",
    "\n",
    "Vou usar uma analogia com um aluno estudando para uma prova:\n",
    "\n",
    "- Treinamento do Modelo (o que j√° fizemos): Foi como o aluno (nosso modelo) estudando o livro (os dados X_train) uma √∫nica vez, do come√ßo ao fim, para aprender para a prova (y_train).\n",
    "\n",
    "- Ajuste de Hiperpar√¢metros (o que vamos fazer): Agora, n√≥s seremos o professor tentando descobrir a melhor ESTRAT√âGIA de estudo para o aluno. O aluno ainda vai estudar o livro todo de uma vez, mas vamos testar diferentes abordagens para ver qual gera o melhor resultado. Por exemplo:\n",
    "\n",
    "   - Estrat√©gia 1: Estude por 1 hora (n_estimators=100) e foque apenas nos conceitos gerais (max_depth=10).\n",
    "\n",
    "   - Estrat√©gia 2: Estude por 3 horas (n_estimators=300) e foque apenas nos conceitos gerais (max_depth=10).\n",
    "\n",
    "   - Estrat√©gia 3: Estude por 1 hora (n_estimators=100), mas agora se aprofunde muito nos detalhes (max_depth=20).\n",
    "\n",
    "Ent√£o, n√£o vamos treinar o mesmo modelo 10 vezes para ele \"lembrar\" mais. Vamos treinar 10 modelos ligeiramente diferentes (com estrat√©gias de estudo/hiperpar√¢metros diferentes) e, no final, escolher o melhor deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e686cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a busca pelos melhores hiperpar√¢metros... (Isso pode levar alguns minutos)\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Busca finalizada!\n",
      "Melhores hiperpar√¢metros encontrados:\n",
      "{'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Melhor MAE (Erro M√©dio Absoluto) na valida√ß√£o cruzada: ‚Ç¨ 29,196.69\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 6: Otimiza√ß√£o do Modelo com GridSearchCV ---\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Definir a grade de hiperpar√¢metros que queremos testar\n",
    "# Estes s√£o os \"bot√µes\" do nosso RandomForest que vamos ajustar.\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],     # N√∫mero de √°rvores na floresta\n",
    "    'max_depth': [10, 20, None],    # Profundidade m√°xima de cada √°rvore\n",
    "    'min_samples_split': [2, 5]     # N√∫mero m√≠nimo de amostras para dividir um n√≥\n",
    "}\n",
    "\n",
    "# 2. Criar o objeto GridSearchCV\n",
    "#   - estimator: nosso modelo base\n",
    "#   - param_grid: nossa grade de testes\n",
    "#   - cv=5: valida√ß√£o cruzada com 5 \"dobras\"\n",
    "#   - scoring='neg_mean_absolute_error': a m√©trica que queremos otimizar. Usamos o 'negativo' porque o GridSearch tenta maximizar, e n√≥s queremos minimizar o erro.\n",
    "#   - n_jobs=-1: usa todos os processadores do seu computador para acelerar o processo.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= RandomForestRegressor(random_state=42),\n",
    "    param_grid= param_grid,\n",
    "    cv= 5,\n",
    "    scoring= 'neg_mean_absolute_error',\n",
    "    n_jobs= -1,\n",
    "    verbose= 2 # Mostra o que ele est√° fazendo em tempo real\n",
    ")\n",
    "\n",
    "# 3. Executar a busca\n",
    "# Esta √© a parte que vai demorar. Ele vai treinar 12 combina√ß√µes * 5 vezes = 60 modelos!\n",
    "print(\"Iniciando a busca pelos melhores hiperpar√¢metros... (Isso pode levar alguns minutos)\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Exibir os melhores resultados\n",
    "print(\"\\nBusca finalizada!\")\n",
    "print(\"Melhores hiperpar√¢metros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# O resultado do best_score_ vir√° negativo, basta pegar o valor absoluto\n",
    "best_mae = -grid_search.best_score_\n",
    "print(f\"\\nMelhor MAE (Erro M√©dio Absoluto) na valida√ß√£o cruzada: ‚Ç¨ {best_mae:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59796066",
   "metadata": {},
   "source": [
    "## Etapa 7: Treinando e Avaliando o Modelo Final Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fdf46309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo final com os melhores par√¢metros...\n",
      "Modelo final treinado com sucesso! üèÜ\n",
      "\n",
      "--- Avalia√ß√£o Final do Modelo Otimizado (nos dados de teste) ---\n",
      "Erro M√©dio Absoluto (MAE) Final: ‚Ç¨ 28,818.08\n",
      "Coeficiente de Determina√ß√£o (R¬≤) Final: 62.37%\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 7: Treinando e Avaliando o Modelo Final Otimizado ---\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. Criar o modelo final com os melhores par√¢metros encontrados\n",
    "print(\"Treinando o modelo final com os melhores par√¢metros...\")\n",
    "final_model = RandomForestRegressor(\n",
    "    n_estimators= 100,\n",
    "    max_depth= 10,\n",
    "    min_samples_split= 2,\n",
    "    random_state= 42,\n",
    "    n_jobs=-1 # Usa todos os processadores para o treino final ser mais r√°pido\n",
    ")\n",
    "\n",
    "# 2. Treinar o modelo final com TODOS os dados de treino\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Modelo final treinado com sucesso! üèÜ\")\n",
    "\n",
    "# 3. Avaliar no conjunto de teste (que o modelo nunca viu antes)\n",
    "final_y_pred = final_model.predict(X_test)\n",
    "\n",
    "final_mae = mean_absolute_error(y_test, final_y_pred)\n",
    "final_r2 = r2_score(y_test, final_y_pred)\n",
    "\n",
    "# 4. Exibir os resultados finais do projeto!\n",
    "print(\"\\n--- Avalia√ß√£o Final do Modelo Otimizado (nos dados de teste) ---\")\n",
    "print(f\"Erro M√©dio Absoluto (MAE) Final: ‚Ç¨ {final_mae:,.2f}\")\n",
    "print(f\"Coeficiente de Determina√ß√£o (R¬≤) Final: {final_r2:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad348d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados exportados com sucesso para 'dados_para_powerbi.csv'! ‚úÖ\n",
      "Este arquivo est√° pronto para ser carregado no Power BI.\n"
     ]
    }
   ],
   "source": [
    "# --- C√âLULA FINAL: Exportando os dados para o Power BI ---\n",
    "\n",
    "# Vamos usar a vari√°vel 'df' que cont√©m nosso DataFrame final e limpo.\n",
    "try:\n",
    "    output_csv_path = 'dados_para_powerbi.csv'\n",
    "    \n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Dados exportados com sucesso para '{output_csv_path}'! ‚úÖ\")\n",
    "    print(\"Este arquivo est√° pronto para ser carregado no Power BI.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"Erro: A vari√°vel 'df' n√£o foi encontrada. Certifique-se de que a primeira c√©lula do notebook foi executada.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao exportar: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8f9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
