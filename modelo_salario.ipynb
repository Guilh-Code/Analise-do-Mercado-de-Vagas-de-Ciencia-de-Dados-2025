{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c3e100",
   "metadata": {},
   "source": [
    "### Nosso Objetivo: \n",
    "\n",
    "\n",
    "Criar um modelo de Machine Learning que aprenda com as vagas existentes para prever o salario_avg de uma nova vaga que nunca vimos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "487cc807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados. Shape inicial: (944, 35)\n",
      "Shape após remover salários nulos: (944, 35)\n",
      "Shape após remover outliers: (942, 35)\n",
      "\n",
      "--- Amostra dos Dados Limpos ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>status</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>industry</th>\n",
       "      <th>ownership</th>\n",
       "      <th>company_size</th>\n",
       "      <th>...</th>\n",
       "      <th>tem_scikit_learning</th>\n",
       "      <th>tem_tensorflow</th>\n",
       "      <th>tem_pytorch</th>\n",
       "      <th>tem_azure</th>\n",
       "      <th>tem_gcp</th>\n",
       "      <th>tem_tableau</th>\n",
       "      <th>tem_pandas</th>\n",
       "      <th>tem_git</th>\n",
       "      <th>tem_java</th>\n",
       "      <th>tem_powerbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>Sênior</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>company_003</td>\n",
       "      <td>Grapevine, TX . Hybrid</td>\n",
       "      <td>17 days ago</td>\n",
       "      <td>Bentonville, AR, US</td>\n",
       "      <td>Varejo</td>\n",
       "      <td>Pública</td>\n",
       "      <td>€352.44B</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>Líder</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>company_005</td>\n",
       "      <td>Fort Worth, TX . Hybrid</td>\n",
       "      <td>15 days ago</td>\n",
       "      <td>Detroit, MI, US</td>\n",
       "      <td>Manufatura</td>\n",
       "      <td>Pública</td>\n",
       "      <td>155,030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>Sênior</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>company_007</td>\n",
       "      <td>Austin, TX . Toronto, Ontario, Canada . Kirkla...</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>Redwood City, CA, US</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>Pública</td>\n",
       "      <td>25,930</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>Sênior</td>\n",
       "      <td>Híbrido</td>\n",
       "      <td>company_008</td>\n",
       "      <td>Chicago, IL . Scottsdale, AZ . Austin, TX . Hy...</td>\n",
       "      <td>8 days ago</td>\n",
       "      <td>San Jose, CA, US</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>Pública</td>\n",
       "      <td>34,690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>Não Informado</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>company_009</td>\n",
       "      <td>On-site</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Stamford, CT, US</td>\n",
       "      <td>Finanças</td>\n",
       "      <td>Privada</td>\n",
       "      <td>1,800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_title seniority_level      status      company  \\\n",
       "0  Cientista de Dados          Sênior     Híbrido  company_003   \n",
       "1  Cientista de Dados           Líder     Híbrido  company_005   \n",
       "2  Cientista de Dados          Sênior  Presencial  company_007   \n",
       "3  Cientista de Dados          Sênior     Híbrido  company_008   \n",
       "4  Cientista de Dados   Não Informado  Presencial  company_009   \n",
       "\n",
       "                                            location    post_date  \\\n",
       "0                             Grapevine, TX . Hybrid  17 days ago   \n",
       "1                            Fort Worth, TX . Hybrid  15 days ago   \n",
       "2  Austin, TX . Toronto, Ontario, Canada . Kirkla...  a month ago   \n",
       "3  Chicago, IL . Scottsdale, AZ . Austin, TX . Hy...   8 days ago   \n",
       "4                                            On-site   3 days ago   \n",
       "\n",
       "            headquarter    industry ownership company_size  ...  \\\n",
       "0   Bentonville, AR, US      Varejo   Pública     €352.44B  ...   \n",
       "1       Detroit, MI, US  Manufatura   Pública      155,030  ...   \n",
       "2  Redwood City, CA, US  Tecnologia   Pública       25,930  ...   \n",
       "3      San Jose, CA, US  Tecnologia   Pública       34,690  ...   \n",
       "4      Stamford, CT, US    Finanças   Privada        1,800  ...   \n",
       "\n",
       "  tem_scikit_learning tem_tensorflow tem_pytorch  tem_azure  tem_gcp  \\\n",
       "0                   0              1           0          0        0   \n",
       "1                   0              0           0          0        0   \n",
       "2                   0              0           0          0        1   \n",
       "3                   0              0           0          0        0   \n",
       "4                   0              0           0          0        0   \n",
       "\n",
       "   tem_tableau tem_pandas tem_git  tem_java  tem_powerbi  \n",
       "0            0          0       0         0            0  \n",
       "1            0          0       0         0            0  \n",
       "2            0          0       1         0            0  \n",
       "3            0          0       0         0            0  \n",
       "4            0          0       0         0            0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# --- ETAPA DE CARREGAMENTO E LIMPEZA INICIAL ---\n",
    "\n",
    "# Configuração\n",
    "db_file_path = 'data_science_jobs.db'\n",
    "table_name = 'job_postings'\n",
    "\n",
    "# Carregando os Dados\n",
    "conn = sqlite3.connect(db_file_path)\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Dados carregados. Shape inicial: {df.shape}\")\n",
    "\n",
    "# --- LIMPEZA E VALIDAÇÃO ---\n",
    "\n",
    "# 1. (BOA PRÁTICA) Remover linhas onde o alvo (salario_avg) é nulo\n",
    "df.dropna(subset=['salario_avg'], inplace=True)\n",
    "print(f\"Shape após remover salários nulos: {df.shape}\")\n",
    "\n",
    "# 2. (A SOLUÇÃO FINAL) Remover outliers extremos de salário\n",
    "df = df[df['salario_avg'] < 2000000] # Mantém apenas as linhas com salário ABAIXO de 2 milhões\n",
    "print(f\"Shape após remover outliers: {df.shape}\")\n",
    "\n",
    "\n",
    "# Exibe as 5 primeiras linhas do DataFrame limpo para verificação\n",
    "print(\"\\n--- Amostra dos Dados Limpos ---\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69651a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verificação Geral do DataFrame (df.info()) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 942 entries, 0 to 943\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   job_title             942 non-null    object \n",
      " 1   seniority_level       942 non-null    object \n",
      " 2   status                942 non-null    object \n",
      " 3   company               942 non-null    object \n",
      " 4   location              940 non-null    object \n",
      " 5   post_date             942 non-null    object \n",
      " 6   headquarter           942 non-null    object \n",
      " 7   industry              942 non-null    object \n",
      " 8   ownership             895 non-null    object \n",
      " 9   company_size          942 non-null    object \n",
      " 10  revenue               927 non-null    object \n",
      " 11  salary                942 non-null    object \n",
      " 12  skills                942 non-null    object \n",
      " 13  salario_min           942 non-null    float64\n",
      " 14  salario_max           942 non-null    float64\n",
      " 15  salario_avg           942 non-null    float64\n",
      " 16  estado                561 non-null    object \n",
      " 17  pais                  796 non-null    object \n",
      " 18  tem_python            942 non-null    int64  \n",
      " 19  tem_sql               942 non-null    int64  \n",
      " 20  tem_r                 942 non-null    int64  \n",
      " 21  tem_machine_learning  942 non-null    int64  \n",
      " 22  tem_aws               942 non-null    int64  \n",
      " 23  tem_spark             942 non-null    int64  \n",
      " 24  tem_deep_learning     942 non-null    int64  \n",
      " 25  tem_scikit_learning   942 non-null    int64  \n",
      " 26  tem_tensorflow        942 non-null    int64  \n",
      " 27  tem_pytorch           942 non-null    int64  \n",
      " 28  tem_azure             942 non-null    int64  \n",
      " 29  tem_gcp               942 non-null    int64  \n",
      " 30  tem_tableau           942 non-null    int64  \n",
      " 31  tem_pandas            942 non-null    int64  \n",
      " 32  tem_git               942 non-null    int64  \n",
      " 33  tem_java              942 non-null    int64  \n",
      " 34  tem_powerbi           942 non-null    int64  \n",
      "dtypes: float64(3), int64(17), object(15)\n",
      "memory usage: 264.9+ KB\n",
      "\n",
      "\n",
      "--- Resumo Estatístico Completo do DataFrame (df.describe()) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>status</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>industry</th>\n",
       "      <th>ownership</th>\n",
       "      <th>company_size</th>\n",
       "      <th>...</th>\n",
       "      <th>tem_scikit_learning</th>\n",
       "      <th>tem_tensorflow</th>\n",
       "      <th>tem_pytorch</th>\n",
       "      <th>tem_azure</th>\n",
       "      <th>tem_gcp</th>\n",
       "      <th>tem_tableau</th>\n",
       "      <th>tem_pandas</th>\n",
       "      <th>tem_git</th>\n",
       "      <th>tem_java</th>\n",
       "      <th>tem_powerbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>940</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>895</td>\n",
       "      <td>942</td>\n",
       "      <td>...</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>942.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>420</td>\n",
       "      <td>429</td>\n",
       "      <td>42</td>\n",
       "      <td>197</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>510</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Cientista de Dados</td>\n",
       "      <td>Sênior</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>company_134</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>San Francisco, CA, US</td>\n",
       "      <td>Tecnologia</td>\n",
       "      <td>Pública</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>854</td>\n",
       "      <td>628</td>\n",
       "      <td>363</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>167</td>\n",
       "      <td>91</td>\n",
       "      <td>580</td>\n",
       "      <td>579</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096603</td>\n",
       "      <td>0.175159</td>\n",
       "      <td>0.157113</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>0.111465</td>\n",
       "      <td>0.123142</td>\n",
       "      <td>0.080679</td>\n",
       "      <td>0.069002</td>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.026539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295573</td>\n",
       "      <td>0.380305</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.369032</td>\n",
       "      <td>0.314874</td>\n",
       "      <td>0.328775</td>\n",
       "      <td>0.272487</td>\n",
       "      <td>0.253592</td>\n",
       "      <td>0.267517</td>\n",
       "      <td>0.160818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 job_title seniority_level      status      company  \\\n",
       "count                  942             942         942          942   \n",
       "unique                   5               5           4          420   \n",
       "top     Cientista de Dados          Sênior  Presencial  company_134   \n",
       "freq                   854             628         363           30   \n",
       "mean                   NaN             NaN         NaN          NaN   \n",
       "std                    NaN             NaN         NaN          NaN   \n",
       "min                    NaN             NaN         NaN          NaN   \n",
       "25%                    NaN             NaN         NaN          NaN   \n",
       "50%                    NaN             NaN         NaN          NaN   \n",
       "75%                    NaN             NaN         NaN          NaN   \n",
       "max                    NaN             NaN         NaN          NaN   \n",
       "\n",
       "                           location    post_date            headquarter  \\\n",
       "count                           940          942                    942   \n",
       "unique                          429           42                    197   \n",
       "top     Bengaluru, Karnataka, India  a month ago  San Francisco, CA, US   \n",
       "freq                             52          167                     91   \n",
       "mean                            NaN          NaN                    NaN   \n",
       "std                             NaN          NaN                    NaN   \n",
       "min                             NaN          NaN                    NaN   \n",
       "25%                             NaN          NaN                    NaN   \n",
       "50%                             NaN          NaN                    NaN   \n",
       "75%                             NaN          NaN                    NaN   \n",
       "max                             NaN          NaN                    NaN   \n",
       "\n",
       "          industry ownership company_size  ... tem_scikit_learning  \\\n",
       "count          942       895          942  ...          942.000000   \n",
       "unique           8         2          510  ...                 NaN   \n",
       "top     Tecnologia   Pública          900  ...                 NaN   \n",
       "freq           580       579           18  ...                 NaN   \n",
       "mean           NaN       NaN          NaN  ...            0.096603   \n",
       "std            NaN       NaN          NaN  ...            0.295573   \n",
       "min            NaN       NaN          NaN  ...            0.000000   \n",
       "25%            NaN       NaN          NaN  ...            0.000000   \n",
       "50%            NaN       NaN          NaN  ...            0.000000   \n",
       "75%            NaN       NaN          NaN  ...            0.000000   \n",
       "max            NaN       NaN          NaN  ...            1.000000   \n",
       "\n",
       "       tem_tensorflow tem_pytorch   tem_azure     tem_gcp  tem_tableau  \\\n",
       "count      942.000000  942.000000  942.000000  942.000000   942.000000   \n",
       "unique            NaN         NaN         NaN         NaN          NaN   \n",
       "top               NaN         NaN         NaN         NaN          NaN   \n",
       "freq              NaN         NaN         NaN         NaN          NaN   \n",
       "mean         0.175159    0.157113    0.162420    0.111465     0.123142   \n",
       "std          0.380305    0.364100    0.369032    0.314874     0.328775   \n",
       "min          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "25%          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "50%          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "75%          0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "max          1.000000    1.000000    1.000000    1.000000     1.000000   \n",
       "\n",
       "        tem_pandas     tem_git    tem_java  tem_powerbi  \n",
       "count   942.000000  942.000000  942.000000   942.000000  \n",
       "unique         NaN         NaN         NaN          NaN  \n",
       "top            NaN         NaN         NaN          NaN  \n",
       "freq           NaN         NaN         NaN          NaN  \n",
       "mean      0.080679    0.069002    0.077495     0.026539  \n",
       "std       0.272487    0.253592    0.267517     0.160818  \n",
       "min       0.000000    0.000000    0.000000     0.000000  \n",
       "25%       0.000000    0.000000    0.000000     0.000000  \n",
       "50%       0.000000    0.000000    0.000000     0.000000  \n",
       "75%       0.000000    0.000000    0.000000     0.000000  \n",
       "max       1.000000    1.000000    1.000000     1.000000  \n",
       "\n",
       "[11 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Coloque esta célula logo após o carregamento inicial do df\n",
    "\n",
    "print(\"--- Verificação Geral do DataFrame (df.info()) ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\\n--- Resumo Estatístico Completo do DataFrame (df.describe()) ---\")\n",
    "# O include='all' mostra estatísticas para colunas de texto e numéricas\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64118a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vaga(s) com Salário Extremo Encontrada(s) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>status</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>post_date</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>industry</th>\n",
       "      <th>ownership</th>\n",
       "      <th>company_size</th>\n",
       "      <th>...</th>\n",
       "      <th>tem_scikit_learning</th>\n",
       "      <th>tem_tensorflow</th>\n",
       "      <th>tem_pytorch</th>\n",
       "      <th>tem_azure</th>\n",
       "      <th>tem_gcp</th>\n",
       "      <th>tem_tableau</th>\n",
       "      <th>tem_pandas</th>\n",
       "      <th>tem_git</th>\n",
       "      <th>tem_java</th>\n",
       "      <th>tem_powerbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_title, seniority_level, status, company, location, post_date, headquarter, industry, ownership, company_size, revenue, salary, skills, salario_min, salario_max, salario_avg, estado, pais, tem_python, tem_sql, tem_r, tem_machine_learning, tem_aws, tem_spark, tem_deep_learning, tem_scikit_learning, tem_tensorflow, tem_pytorch, tem_azure, tem_gcp, tem_tableau, tem_pandas, tem_git, tem_java, tem_powerbi]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vamos encontrar a(s) vaga(s) com salário astronômico\n",
    "outliers = df[df['salario_avg'] > 2000000] # Filtra o DataFrame para salários maiores que 2 milhões\n",
    "\n",
    "print(\"--- Vaga(s) com Salário Extremo Encontrada(s) ---\")\n",
    "display(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612383d1",
   "metadata": {},
   "source": [
    "### Vamos dividir nossa construção do modelo em etapas claras:\n",
    "\n",
    "- Etapa 1: Seleção e Preparação das Features (Onde estamos agora).\n",
    "\n",
    "- Etapa 2: Pré-processamento e Codificação (Transformando tudo em números).\n",
    "\n",
    "- Etapa 3: Divisão dos Dados (Treino e Teste).\n",
    "\n",
    "- Etapa 4: Escolha e Treinamento do Modelo.\n",
    "\n",
    "- Etapa 5: Avaliação do Modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ffb798",
   "metadata": {},
   "source": [
    "## Etapa 1: Selecionando as Armas (Features) e o Alvo (Target)\n",
    "\n",
    "1. O Alvo (Target): O que você quer que eu aprenda a prever? ( y )\n",
    "\n",
    "2. As Pistas (Features): Que informações você vai me dar para que eu possa fazer a previsão? ( x )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74dc18b",
   "metadata": {},
   "source": [
    "### O nosso Alvo (y): \n",
    "É fácil. Queremos prever o salário. A coluna perfeita para isso é a salario_avg que nós criamos.\n",
    "\n",
    "\n",
    "### As nossas Pistas (X): \n",
    "Aqui entra a parte estratégica. Quais colunas do nosso banco de dados são pistas úteis para adivinhar o salário?\n",
    "\n",
    "- job_title, seniority_level, status, industry: Com certeza! São muito importantes.\n",
    "- pais, estado: Sim, o local influencia no salário.\n",
    "- tem_python, tem_sql, etc.: Absolutamente! As habilidades são um fator chave.\n",
    "\n",
    "E quais colunas devemos EXCLUIR das pistas?\n",
    "\n",
    "- salary, salario_min, salario_max, salario_avg: NUNCA podemos usar o próprio alvo ou suas variações como uma pista. Seria como dar a resposta da prova para o aluno. Isso se chama data leakage (vazamento de dados) e é o erro número 1 em projetos de ML.\n",
    "- location, skills: As colunas de texto originais. Elas são \"sujas\" e nós já extraímos as informações importantes delas para as novas colunas.\n",
    "- company, post_date, headquarter: São identificadores, datas em formato de texto ou informações que já foram representadas de forma melhor (pais, estado). Por agora, vamos deixá-las de fora para manter nosso primeiro modelo simples e forte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fef75c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Amostra do Alvo (y) ---\n",
      "0    150705.0\n",
      "1    118733.0\n",
      "2    127273.0\n",
      "3    153599.5\n",
      "4    171254.5\n",
      "Name: salario_avg, dtype: float64\n",
      "\n",
      "--- Amostra das Features (X) ---\n",
      "            job_title seniority_level      status    industry ownership  \\\n",
      "0  Cientista de Dados          Sênior     Híbrido      Varejo   Pública   \n",
      "1  Cientista de Dados           Líder     Híbrido  Manufatura   Pública   \n",
      "2  Cientista de Dados          Sênior  Presencial  Tecnologia   Pública   \n",
      "3  Cientista de Dados          Sênior     Híbrido  Tecnologia   Pública   \n",
      "4  Cientista de Dados   Não Informado  Presencial    Finanças   Privada   \n",
      "\n",
      "            pais         estado  tem_python  tem_sql  tem_r  ...  \\\n",
      "0             US             TX           1        0      1  ...   \n",
      "1             US             TX           1        1      1  ...   \n",
      "2             CA  Não Informado           1        1      0  ...   \n",
      "3             US             IL           1        1      1  ...   \n",
      "4  Não Informado  Não Informado           0        0      0  ...   \n",
      "\n",
      "   tem_scikit_learning  tem_tensorflow  tem_pytorch  tem_azure  tem_gcp  \\\n",
      "0                    0               1            0          0        0   \n",
      "1                    0               0            0          0        0   \n",
      "2                    0               0            0          0        1   \n",
      "3                    0               0            0          0        0   \n",
      "4                    0               0            0          0        0   \n",
      "\n",
      "   tem_tableau  tem_pandas  tem_git  tem_java  tem_powerbi  \n",
      "0            0           0        0         0            0  \n",
      "1            0           0        0         0            0  \n",
      "2            0           0        1         0            0  \n",
      "3            0           0        0         0            0  \n",
      "4            0           0        0         0            0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Formato de X (linhas, colunas): (942, 24)\n",
      "Formato de y (linhas,): (942,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilh\\AppData\\Local\\Temp\\ipykernel_11672\\3174086559.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(\"Não Informado\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ---  Etapa 1: Seleção de Features e target  ---\n",
    "\n",
    "# 1. Definir o Alvo (Target)\n",
    "# A variável 'y' vai conter apenas a coluna que queremos prever.\n",
    "target = 'salario_avg'\n",
    "y = df[target]\n",
    "\n",
    "# 2. Definir as Pistas (Features)\n",
    "# Criamos uma lista com os nomes de todas as colunas que servirão como \"pistas\" para o modelo.\n",
    "features = [\n",
    "    'job_title', 'seniority_level', 'status', 'industry', 'ownership',\n",
    "    'pais', 'estado',\n",
    "    'tem_python', 'tem_sql', 'tem_r', 'tem_machine_learning', 'tem_aws',\n",
    "    'tem_spark', 'tem_deep_learning', 'tem_scikit_learning', 'tem_tensorflow',\n",
    "    'tem_pytorch', 'tem_azure', 'tem_gcp', 'tem_tableau', 'tem_pandas',\n",
    "    'tem_git', 'tem_java', 'tem_powerbi'\n",
    "]\n",
    "X = df[features]\n",
    "\n",
    "# Tratamento de valores nulos ANTES do encoding\n",
    "X.fillna(\"Não Informado\", inplace=True)\n",
    "\n",
    "# 3. Verificar o resultado\n",
    "print(\"--- Amostra do Alvo (y) ---\")\n",
    "print(y.head())\n",
    "print(\"\\n--- Amostra das Features (X) ---\")\n",
    "print(X.head())\n",
    "\n",
    "print(f\"\\nFormato de X (linhas, colunas): {X.shape}\")\n",
    "print(f\"Formato de y (linhas,): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353204a",
   "metadata": {},
   "source": [
    "## Etapa 2: Pré-processamento e Codificação (One-Hot Encoding)\n",
    "\n",
    "O Problema: Temos colunas como job_title com valores 'Cientista de Dados', 'Engenheiro de Dados', etc. Não podemos simplesmente substituir 'Cientista de Dados' por 1 e 'Engenheiro de Dados' por 2, pois isso criaria uma relação matemática falsa (como se um Engenheiro fosse \"o dobro\" de um Cientista), o que confundiria o modelo.\n",
    "\n",
    "A Solução: One-Hot Encoding\n",
    "A técnica correta se chama One-Hot Encoding. É um nome complicado para uma ideia muito simples, que eu chamo de \"Técnica do Interruptor\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc59c64",
   "metadata": {},
   "source": [
    "Imagine a coluna status com 3 opções: 'Presencial', 'Híbrido', 'Remoto'.\n",
    "O One-Hot Encoding vai fazer o seguinte:\n",
    "\n",
    "1. Ele apaga a coluna status original.\n",
    "\n",
    "2. Ele cria novas colunas, uma para cada opção possível, como se fossem interruptores: status_Presencial, status_Híbrido, status_Remoto.\n",
    "\n",
    "3. Para cada vaga, ele \"liga\" (1) apenas o interruptor correspondente e deixa \n",
    "os outros \"desligados\" (0).\n",
    "\n",
    "\n",
    "Isso transforma uma única coluna de texto em múltiplas colunas de 0s e 1s, sem criar relações falsas. O modelo agora entende perfeitamente a categoria de cada vaga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b15418f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Amostra das Features após o One-Hot Encoding ---\n",
      "   tem_python  tem_sql  tem_r  tem_machine_learning  tem_aws  tem_spark  \\\n",
      "0           1        0      1                     1        0          1   \n",
      "1           1        1      1                     1        0          1   \n",
      "2           1        1      0                     1        1          0   \n",
      "3           1        1      1                     0        0          0   \n",
      "4           0        0      0                     0        0          0   \n",
      "\n",
      "   tem_deep_learning  tem_scikit_learning  tem_tensorflow  tem_pytorch  ...  \\\n",
      "0                  0                    0               1            0  ...   \n",
      "1                  0                    0               0            0  ...   \n",
      "2                  1                    0               0            0  ...   \n",
      "3                  0                    0               0            0  ...   \n",
      "4                  0                    0               0            0  ...   \n",
      "\n",
      "   estado_ON  estado_OR  estado_PA  estado_TN  estado_TX  estado_UN  \\\n",
      "0          0          0          0          0          1          0   \n",
      "1          0          0          0          0          1          0   \n",
      "2          0          0          0          0          0          0   \n",
      "3          0          0          0          0          0          0   \n",
      "4          0          0          0          0          0          0   \n",
      "\n",
      "   estado_US  estado_VA  estado_WA  estado_WI  \n",
      "0          0          0          0          0  \n",
      "1          0          0          0          0  \n",
      "2          0          0          0          0  \n",
      "3          0          0          0          0  \n",
      "4          0          0          0          0  \n",
      "\n",
      "[5 rows x 86 columns]\n",
      "\n",
      "--- Mudança no Formato do DataFrame ---\n",
      "Formato original de X (antes do encoding): (942, 24)\n",
      "Formato de X_encoded (após o encoding): (942, 86)\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 2: Pré-processamento e Codificação (One-Hot Encoding) ---\n",
    "\n",
    "# O pandas tem uma função \"mágica\" para isso chamada get_dummies().\n",
    "# Ela encontra todas as colunas que não são numéricas no DataFrame X e aplica a \"Técnica do Interruptor\".\n",
    "# O parâmetro drop_first=True é uma boa prática para evitar redundância de dados, o que pode ajudar o modelo.\n",
    "X_encoded = pd.get_dummies(X, drop_first=True).astype(int)\n",
    "\n",
    "# --- Verificação ---\n",
    "print(\"--- Amostra das Features após o One-Hot Encoding ---\")\n",
    "print(X_encoded.head())\n",
    "\n",
    "print(\"\\n--- Mudança no Formato do DataFrame ---\")\n",
    "print(f\"Formato original de X (antes do encoding): {X.shape}\")\n",
    "print(f\"Formato de X_encoded (após o encoding): {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f44dcd",
   "metadata": {},
   "source": [
    "## Etapa 3: Divisão dos Dados (Treino e Teste)\n",
    "\n",
    "Como falamos antes, precisamos separar nossos dados. Vamos usar a maior parte deles (geralmente 80%) para treinar o modelo. Os 20% restantes vamos guardar em um \"cofre\" e só usar no final, para fazer uma \"prova final\" e ver se o modelo é bom com dados que ele nunca viu antes.\n",
    "\n",
    "A biblioteca scikit-learn, que é o padrão da indústria para ML em Python, tem uma função perfeita para isso: a train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06af2e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Formato dos Dados de Treino ---\n",
      "Formato de X_train: (753, 86)\n",
      "Formato de y_train: (753,)\n",
      "\n",
      "--- Formato dos Dados de Teste ---\n",
      "Formato de X_test: (189, 86)\n",
      "Formato de y_test: (189,)\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 3: Divisão dos Dados em Treino e Teste ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Esta função vai embaralhar e dividir nossos dados em 4 partes:\n",
    "\n",
    "# X_train, y_train: 80% dos dados para o modelo aprender.\n",
    "# X_test, y_test: 20% dos dados para testarmos o modelo no final.\n",
    "# random_state=42: É como uma \"semente\" para o embaralhamento. Usar um número fixo grande que a divisão seja sempre a mesma, tornando nosso experimento reprodutível.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Verificação ---\n",
    "print(\"--- Formato dos Dados de Treino ---\")\n",
    "print(f\"Formato de X_train: {X_train.shape}\")\n",
    "print(f\"Formato de y_train: {y_train.shape}\")\n",
    "\n",
    "print(\"\\n--- Formato dos Dados de Teste ---\")\n",
    "print(f\"Formato de X_test: {X_test.shape}\")\n",
    "print(f\"Formato de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2c972",
   "metadata": {},
   "source": [
    "O \"Desempacotamento\" Mágico do Python\n",
    "A função train_test_split não retorna 4 variáveis soltas. Na verdade, ela retorna uma única coisa: uma estrutura de dados chamada tupla, que contém 4 elementos dentro dela, sempre na mesma ordem.\n",
    "\n",
    "A documentação da scikit-learn garante que a ordem de retorno é sempre:\n",
    "\n",
    "1. O conjunto de treino das features (X_train)\n",
    "\n",
    "2. O conjunto de teste das features (X_test)\n",
    "\n",
    "3. O conjunto de treino do alvo (y_train)\n",
    "\n",
    "4. O conjunto de teste do alvo (y_test)\n",
    "\n",
    "Ordem que escrevemos X_train, X_test, y_train, y_test é fixa e obrigatória."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b1611",
   "metadata": {},
   "source": [
    "## Etapa 4: Escolhendo o Cérebro (O Algoritmo) e Treinando o Modelo\n",
    "\n",
    "Existem dezenas de algoritmos, cada um com uma forma diferente de \"pensar\". Para o nosso primeiro projeto, vamos começar com um dos mais fundamentais e importantes: a Regressão Linear (LinearRegression).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b89a41",
   "metadata": {},
   "source": [
    "O que é a Regressão Linear?\n",
    "Pense nela como um detetive que tenta encontrar a \"fórmula\" ou a \"receita\" do salário. Ele vai olhar para todas as nossas features (tem_python, seniority_level_Sênior, pais_US, etc.) e atribuir um \"peso\" para cada uma.\n",
    "\n",
    "- Ele pode aprender que seniority_level_Sênior tem um peso positivo alto (aumenta o salário).\n",
    "\n",
    "- Pode aprender que tem_python tem um peso positivo moderado.\n",
    "\n",
    "- Pode aprender que job_title_Analista de Dados tem um peso negativo (diminui o salário em relação à média).\n",
    "\n",
    "O \"treinamento\" do modelo é o processo de encontrar os valores exatos para todos esses pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7c82144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspeção Profunda dos Dados de Treino ---\n",
      "Tipo de dado de X_train (array interno): int32\n",
      "Tipo de dado de y_train (array interno): float64\n",
      "Todos os valores em X_train são finitos? True\n",
      "Todos os valores em y_train são finitos? True\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- CÉLULA DE DIAGNÓSTICO DE NÍVEL PROFUNDO ---\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Inspeção Profunda dos Dados de Treino ---\")\n",
    "\n",
    "# 1. Verificar o tipo de dado do array numérico que o modelo realmente recebe\n",
    "print(f\"Tipo de dado de X_train (array interno): {X_train.values.dtype}\")\n",
    "print(f\"Tipo de dado de y_train (array interno): {y_train.values.dtype}\")\n",
    "\n",
    "# 2. A verificação definitiva: TODOS os valores são finitos (não-nulos E não-infinitos)?\n",
    "print(f\"Todos os valores em X_train são finitos? {np.isfinite(X_train.values).all()}\")\n",
    "print(f\"Todos os valores em y_train são finitos? {np.isfinite(y_train.values).all()}\")\n",
    "print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "974d9ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo RandomForest treinado com sucesso! 🌳🌳🌳\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 4: Escolha e Treinamento do Modelo (VERSÃO COM RANDOM FOREST) ---\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. Criar o modelo\n",
    "# Trocamos o cérebro! Em vez de LinearRegression, usamos RandomForestRegressor.\n",
    "# random_state=42 garante que a \"floresta\" seja sempre criada da mesma forma, para reprodutibilidade.\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 2. Treinar o modelo\n",
    "# A MÁGICA: O comando .fit() é EXATAMENTE O MESMO!\n",
    "# O scikit-learn tem uma API consistente, não importa o quão complexo seja o modelo.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Verificação\n",
    "print(\"Modelo RandomForest treinado com sucesso! 🌳🌳🌳\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd08b7e",
   "metadata": {},
   "source": [
    "## Etapa 5: A Prova Final (Avaliando o Desempenho do Modelo)\n",
    "\n",
    "No entanto, para um modelo de Regressão (que prevê um número, como o salário), não usamos \"porcentagem de acerto\", porque seria impossível o modelo acertar o valor exato sempre (prever €145.231,78 em vez de €145.231,80 já seria um \"erro\").\n",
    "\n",
    "Em vez disso, usamos outras métricas para saber se ele está \"chegando perto\". As duas mais importantes para nós serão:\n",
    "\n",
    "### 1. MAE (Mean Absolute Error - Erro Médio Absoluto):\n",
    "\n",
    "- O que é? Em média, quantos euros o nosso modelo erra a previsão (para mais ou para menos).\n",
    "\n",
    "- Como ler? Se o MAE for €10.000, significa que, na média, as previsões do nosso modelo estão a €10.000 de distância do salário real. Um MAE menor é melhor.\n",
    "\n",
    "### 2. R² (R-quadrado ou Coeficiente de Determinação):\n",
    "\n",
    "- O que é? Essa é a métrica que mais se aproxima da sua ideia de \"porcentagem\". Ela nos diz que porcentagem da variação dos salários o nosso modelo consegue explicar com base nas features que demos a ele.\n",
    "\n",
    "- Como ler? O valor vai de 0 a 1 (ou 0% a 100%). Um R² de 0.65, por exemplo, significa que nosso modelo consegue explicar 65% dos motivos que fazem um salário ser alto ou baixo. O resto (35%) se deve a fatores que não estão nos nossos dados (sorte, habilidade de negociação, etc.). Um R² maior é melhor. Para um problema complexo como salários, um R² acima de 0.60 ou 0.70 já é considerado um bom resultado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2f3dc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avaliação do Modelo RandomForest ---\n",
      "Erro Médio Absoluto (MAE): € 29,514.79\n",
      "Coeficiente de Determinação (R²): 60.07%\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 5: Avaliação do Modelo ---\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1. Fazer as previsões no conjunto de teste\n",
    "# Usamos o comando .predict() nos dados de teste (X_test) para ver o que o modelo \"adivinha\".\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calcular as métricas\n",
    "# Comparamos as previsões (y_pred) com as respostas reais (y_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 3. Exibir os resultados\n",
    "print(\"--- Avaliação do Modelo RandomForest ---\")\n",
    "print(f\"Erro Médio Absoluto (MAE): € {mae:,.2f}\")\n",
    "print(f\"Coeficiente de Determinação (R²): {r2:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b0b06",
   "metadata": {},
   "source": [
    "## Etapa 6: Otimizando o Modelo (Ajuste de Hiperparâmetros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dca8b",
   "metadata": {},
   "source": [
    "### o Ajuste de Hiperparâmetros.\n",
    "\n",
    "Vou usar uma analogia com um aluno estudando para uma prova:\n",
    "\n",
    "- Treinamento do Modelo (o que já fizemos): Foi como o aluno (nosso modelo) estudando o livro (os dados X_train) uma única vez, do começo ao fim, para aprender para a prova (y_train).\n",
    "\n",
    "- Ajuste de Hiperparâmetros (o que vamos fazer): Agora, nós seremos o professor tentando descobrir a melhor ESTRATÉGIA de estudo para o aluno. O aluno ainda vai estudar o livro todo de uma vez, mas vamos testar diferentes abordagens para ver qual gera o melhor resultado. Por exemplo:\n",
    "\n",
    "   - Estratégia 1: Estude por 1 hora (n_estimators=100) e foque apenas nos conceitos gerais (max_depth=10).\n",
    "\n",
    "   - Estratégia 2: Estude por 3 horas (n_estimators=300) e foque apenas nos conceitos gerais (max_depth=10).\n",
    "\n",
    "   - Estratégia 3: Estude por 1 hora (n_estimators=100), mas agora se aprofunde muito nos detalhes (max_depth=20).\n",
    "\n",
    "Então, não vamos treinar o mesmo modelo 10 vezes para ele \"lembrar\" mais. Vamos treinar 10 modelos ligeiramente diferentes (com estratégias de estudo/hiperparâmetros diferentes) e, no final, escolher o melhor deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e686cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a busca pelos melhores hiperparâmetros... (Isso pode levar alguns minutos)\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Busca finalizada!\n",
      "Melhores hiperparâmetros encontrados:\n",
      "{'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Melhor MAE (Erro Médio Absoluto) na validação cruzada: € 29,196.69\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 6: Otimização do Modelo com GridSearchCV ---\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Definir a grade de hiperparâmetros que queremos testar\n",
    "# Estes são os \"botões\" do nosso RandomForest que vamos ajustar.\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],     # Número de árvores na floresta\n",
    "    'max_depth': [10, 20, None],    # Profundidade máxima de cada árvore\n",
    "    'min_samples_split': [2, 5]     # Número mínimo de amostras para dividir um nó\n",
    "}\n",
    "\n",
    "# 2. Criar o objeto GridSearchCV\n",
    "#   - estimator: nosso modelo base\n",
    "#   - param_grid: nossa grade de testes\n",
    "#   - cv=5: validação cruzada com 5 \"dobras\"\n",
    "#   - scoring='neg_mean_absolute_error': a métrica que queremos otimizar. Usamos o 'negativo' porque o GridSearch tenta maximizar, e nós queremos minimizar o erro.\n",
    "#   - n_jobs=-1: usa todos os processadores do seu computador para acelerar o processo.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= RandomForestRegressor(random_state=42),\n",
    "    param_grid= param_grid,\n",
    "    cv= 5,\n",
    "    scoring= 'neg_mean_absolute_error',\n",
    "    n_jobs= -1,\n",
    "    verbose= 2 # Mostra o que ele está fazendo em tempo real\n",
    ")\n",
    "\n",
    "# 3. Executar a busca\n",
    "# Esta é a parte que vai demorar. Ele vai treinar 12 combinações * 5 vezes = 60 modelos!\n",
    "print(\"Iniciando a busca pelos melhores hiperparâmetros... (Isso pode levar alguns minutos)\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Exibir os melhores resultados\n",
    "print(\"\\nBusca finalizada!\")\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# O resultado do best_score_ virá negativo, basta pegar o valor absoluto\n",
    "best_mae = -grid_search.best_score_\n",
    "print(f\"\\nMelhor MAE (Erro Médio Absoluto) na validação cruzada: € {best_mae:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59796066",
   "metadata": {},
   "source": [
    "## Etapa 7: Treinando e Avaliando o Modelo Final Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fdf46309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo final com os melhores parâmetros...\n",
      "Modelo final treinado com sucesso! 🏆\n",
      "\n",
      "--- Avaliação Final do Modelo Otimizado (nos dados de teste) ---\n",
      "Erro Médio Absoluto (MAE) Final: € 28,818.08\n",
      "Coeficiente de Determinação (R²) Final: 62.37%\n"
     ]
    }
   ],
   "source": [
    "# --- Etapa 7: Treinando e Avaliando o Modelo Final Otimizado ---\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1. Criar o modelo final com os melhores parâmetros encontrados\n",
    "print(\"Treinando o modelo final com os melhores parâmetros...\")\n",
    "final_model = RandomForestRegressor(\n",
    "    n_estimators= 100,\n",
    "    max_depth= 10,\n",
    "    min_samples_split= 2,\n",
    "    random_state= 42,\n",
    "    n_jobs=-1 # Usa todos os processadores para o treino final ser mais rápido\n",
    ")\n",
    "\n",
    "# 2. Treinar o modelo final com TODOS os dados de treino\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Modelo final treinado com sucesso! 🏆\")\n",
    "\n",
    "# 3. Avaliar no conjunto de teste (que o modelo nunca viu antes)\n",
    "final_y_pred = final_model.predict(X_test)\n",
    "\n",
    "final_mae = mean_absolute_error(y_test, final_y_pred)\n",
    "final_r2 = r2_score(y_test, final_y_pred)\n",
    "\n",
    "# 4. Exibir os resultados finais do projeto!\n",
    "print(\"\\n--- Avaliação Final do Modelo Otimizado (nos dados de teste) ---\")\n",
    "print(f\"Erro Médio Absoluto (MAE) Final: € {final_mae:,.2f}\")\n",
    "print(f\"Coeficiente de Determinação (R²) Final: {final_r2:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad348d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados exportados com sucesso para 'dados_para_powerbi.csv'! ✅\n",
      "Este arquivo está pronto para ser carregado no Power BI.\n"
     ]
    }
   ],
   "source": [
    "# --- CÉLULA FINAL: Exportando os dados para o Power BI ---\n",
    "\n",
    "# Vamos usar a variável 'df' que contém nosso DataFrame final e limpo.\n",
    "try:\n",
    "    output_csv_path = 'dados_para_powerbi.csv'\n",
    "    \n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"Dados exportados com sucesso para '{output_csv_path}'! ✅\")\n",
    "    print(\"Este arquivo está pronto para ser carregado no Power BI.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"Erro: A variável 'df' não foi encontrada. Certifique-se de que a primeira célula do notebook foi executada.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao exportar: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8f9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
